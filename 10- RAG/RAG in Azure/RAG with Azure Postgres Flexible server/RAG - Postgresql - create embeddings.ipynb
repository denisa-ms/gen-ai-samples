{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Postgres flexible server\n",
    "\n",
    "#### IMPORTANT!! Embeddings Creation - Run this only once !!!\n",
    "You only need to run this once to create the embeddings and save them to Postgres flexible server.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, JSON, Markdown\n",
    "import os\n",
    "\n",
    "# Configure environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure OpenAI API\n",
    "OPENAI_GPT35_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT35_DEPLOYMENT_NAME\")\n",
    "OPENAI_GPT4_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4_DEPLOYMENT_NAME\")\n",
    "OPENAI_GPT4V_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4V_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_DALLE_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DALLE_DEPLOYMENT_NAME\")\n",
    "\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# configure postgres\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\")\n",
    "POSTGRES_DB = os.getenv(\"POSTGRES_DB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingmodel = AzureOpenAIEmbeddings(\n",
    "    deployment=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    chunk_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def calc_embeddings(text):\n",
    "    deployment = OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    txt = text.replace(\"\\n\", \" \")\n",
    "    return embeddingmodel.embed_query(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  1475\n"
     ]
    }
   ],
   "source": [
    "# splitting into 1000 char long chunks with 30 char overlap\n",
    "# split [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=30,\n",
    ")\n",
    "\n",
    "documentName = \"moby dick book\"\n",
    "fileName = \"../data/moby dick.pdf\"\n",
    "loader = PyPDFLoader(fileName)\n",
    "pages = loader.load_and_split(text_splitter=splitter)\n",
    "print(\"Number of pages: \", len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moby dick book</td>\n",
       "      <td>The Project Gutenberg eBook of Moby -Dick; or ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moby dick book</td>\n",
       "      <td>CONTENTS  \\n \\nETYMOLOGY.  \\n \\nEXTRACTS (Supp...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moby dick book</td>\n",
       "      <td>CHAPTER 11. Nightgown.  \\n \\nCHAPTER 12. Biogr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moby dick book</td>\n",
       "      <td>CHAPTER 41. Moby Dick.  \\n \\nCHAPTER 42. The W...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moby dick book</td>\n",
       "      <td>CHAPTER 67. Cutting In.  \\n \\nCHAPTER 68. The ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document_name                                            content embedding\n",
       "0  moby dick book  The Project Gutenberg eBook of Moby -Dick; or ...          \n",
       "1  moby dick book  CONTENTS  \\n \\nETYMOLOGY.  \\n \\nEXTRACTS (Supp...          \n",
       "2  moby dick book  CHAPTER 11. Nightgown.  \\n \\nCHAPTER 12. Biogr...          \n",
       "3  moby dick book  CHAPTER 41. Moby Dick.  \\n \\nCHAPTER 42. The W...          \n",
       "4  moby dick book  CHAPTER 67. Cutting In.  \\n \\nCHAPTER 68. The ...          "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save all the pages into a pandas dataframe\n",
    "df = pd.DataFrame(columns=['document_name', 'content', 'embedding'])\n",
    "for page in pages:\n",
    "    df.loc[len(df.index)] = [documentName, page.page_content, \"\"]  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the embeddings using openAI ada \n",
    "df[\"embedding\"] = df.content.apply(lambda x: calc_embeddings(x))\n",
    "df.to_csv('../data/pg_embeddings.csv', index=False)\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "sslmode = \"require\"\n",
    "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(POSTGRES_HOST, POSTGRES_USER, POSTGRES_DB, POSTGRES_PASSWORD, sslmode)\n",
    "conn = psycopg2.connect(conn_string) \n",
    "print(\"Connection established\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the vector extension in the DB\n",
    "try:\n",
    "    # Start a new transaction\n",
    "    cursor.execute(\"BEGIN;\")\n",
    "\n",
    "    # Check if the extension already exists\n",
    "    extension_query = \"SELECT * FROM pg_extension WHERE extname = 'vector';\"\n",
    "    cursor.execute(extension_query)\n",
    "    extension_exists = cursor.fetchone()\n",
    "\n",
    "    if not extension_exists:\n",
    "        # Extension does not exist, create it\n",
    "        create_extension_query = \"CREATE EXTENSION vector;\"\n",
    "        cursor.execute(create_extension_query)\n",
    "        conn.commit()\n",
    "    else:\n",
    "        # Extension already exists, pass through\n",
    "        pass\n",
    "\n",
    "    # Commit the transaction\n",
    "    cursor.execute(\"COMMIT;\")\n",
    "except Exception as e:\n",
    "    # An error occurred, rollback the transaction\n",
    "    cursor.execute(\"ROLLBACK;\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('VECTOR',)\n"
     ]
    }
   ],
   "source": [
    "# Checking the vector extension exists\n",
    "show_extensions_query = \"SHOW azure.extensions;\"\n",
    "cursor.execute(show_extensions_query)\n",
    "conn.commit()\n",
    "results = cursor.fetchall()\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.psycopg2 import register_vector\n",
    "from psycopg2 import Error\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Register 'pgvector' type for the 'embedding' column\n",
    "register_vector(conn)\n",
    "\n",
    "# Convert the DataFrame to a list of tuples for bulk insertion\n",
    "records = df.to_records(index=False)\n",
    "records_list = records.tolist()\n",
    "\n",
    "table_name = 'embeddings'\n",
    "batch_size = 10\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    document_name TEXT,\n",
    "    content TEXT,\n",
    "    embedding VECTOR\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "insert_query = f\"INSERT INTO {table_name} (document_name, content, embedding) \" \\\n",
    "            f\"VALUES (%s, %s, %s)\"\n",
    "cursor.executemany(insert_query, records_list)\n",
    "conn.commit()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
