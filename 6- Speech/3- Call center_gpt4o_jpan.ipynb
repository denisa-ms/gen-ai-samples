{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o; API Version:2024-10-21\n",
      "Azure OpenAI model is ready to use!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_ENDPOINT=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_KEY=os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_API_VERSION=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_GPT4o_DEPLOYMENT=os.getenv(\"AZURE_OPENAI_GPT4o_DEPLOYMENT\")\n",
    "\n",
    "#init the openai client\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = AZURE_OPENAI_ENDPOINT, \n",
    "  api_key=AZURE_OPENAI_KEY,  \n",
    "  api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "print(f\"Model: {AZURE_OPENAI_GPT4o_DEPLOYMENT}; API Version:{AZURE_OPENAI_API_VERSION}\")\n",
    "print(\"Azure OpenAI model is ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech Service in australiaeast is ready to use!\n"
     ]
    }
   ],
   "source": [
    "SPEECH_KEY = os.getenv(\"SPEECH_KEY\")\n",
    "SPEECH_REGION = os.getenv(\"SPEECH_REGION\")\n",
    "engine_name = \"test\"\n",
    "\n",
    "print(f\"Speech Service in {SPEECH_REGION} is ready to use!\")\n",
    "\n",
    "speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)\n",
    "# Set up Azure Text-to-Speech language \n",
    "speech_config.speech_synthesis_language = \"en-US\"\n",
    "# Set up Azure Speech-to-Text language recognition\n",
    "speech_config.speech_recognition_language = \"en-US\"\n",
    "# Use an absolute path for the log file\n",
    "log_file_path = os.path.abspath(\"./log/log.txt\")\n",
    "speech_config.set_property(speechsdk.PropertyId.Speech_LogFilename, log_file_path)\n",
    "\n",
    "\n",
    "# Set up the voice configuration\n",
    "speech_config.speech_synthesis_voice_name = \"en-US-JennyMultilingualNeural\"\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the speech-to-text function using continuous recognition\n",
    "def speech_to_text():\n",
    "    # Set up the audio configuration\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    # Create a speech recognizer and start the recognition\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    print(\"Say something...\")\n",
    "\n",
    "    done = False\n",
    "    all_results = []\n",
    "\n",
    "    def stop_cb(evt):\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    def recognized_cb(evt):\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            print(\"Recognized: {}\".format(evt.result.text))\n",
    "            all_results.append(evt.result.text)\n",
    "        elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"No speech could be recognized: {}\".format(evt.result.no_match_details))\n",
    "        return \"\"\n",
    "\n",
    "    speech_recognizer.recognized.connect(recognized_cb)\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        pass\n",
    "\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "    return \" \".join(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text-to-speech function\n",
    "def text_to_speech(text):\n",
    "    try:\n",
    "        result = speech_synthesizer.speak_text_async(text).get()\n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(\"Text-to-speech conversion successful.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Error synthesizing audio: {result}\")\n",
    "            return False\n",
    "    except Exception as ex:\n",
    "        print(f\"Error synthesizing audio: {ex}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sentiment(text):\n",
    "    system_message = \"\"\"\n",
    "    You are an AI assistant that helps recognize the sentiment in a given text.\n",
    "    1. Evaluate the given text and provide the category of the sentiment as either positive, negative, or neutral.\n",
    "    2. Do not provide any additional examples to the output, just the category.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_GPT4o_DEPLOYMENT,\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\":system_message},\n",
    "            {\"role\":\"user\",\"content\":text}\n",
    "            ],\n",
    "        temperature=0   \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_from_file_short(filename):\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=filename)\n",
    "    # Creates a speech recognizer using a file as audio input, also specify the speech language\n",
    "    speech_config.speech_recognition_language = \"en-US\"\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of about 30\n",
    "    # seconds of audio is processed. It returns the recognition text as result.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        return result.text\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "def speech_from_file_full(filename):\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=filename)\n",
    "    speech_config.speech_recognition_language = \"en-US\"\n",
    "    \n",
    "    # Creates a speech recognizer using a file as audio input\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # List to store the recognized text\n",
    "    all_results = []\n",
    "\n",
    "    def recognized_cb(evt):\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            print(\"Recognized: {}\".format(evt.result.text))\n",
    "            all_results.append(evt.result.text)\n",
    "        elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"No speech could be recognized: {}\".format(evt.result.no_match_details))\n",
    "\n",
    "    def stop_cb(evt):\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognized.connect(recognized_cb)\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start continuous recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        pass\n",
    "\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "    # Return the concatenated results\n",
    "    return \" \".join(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_GPT4o_DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"\n",
    "             Extract the entities from the text and provide only JSON output.\n",
    "             \n",
    "             {caller_name: \"John\", call_purpose: \"meeting\"}\n",
    "\n",
    "             \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ],\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, target_language):\n",
    "    system_message = \"\"\"You are a helpful assistant that translates text into \"\"\" + target_language + \"\"\".\n",
    "    Answer in a clear and concise manner only translating the text. \n",
    "    Ignore filler words like 'ng', 'uh', etc. and any unnatural sentence breaks. \n",
    "    Ensure the translation flows smoothly and natually while preserving the intended meaning.\n",
    "    Text:\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_GPT4o_DEPLOYMENT,\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\":system_message},\n",
    "            {\"role\":\"user\",\"content\":text}\n",
    "            ],\n",
    "        temperature=0   \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: Hello, thank you for calling Contoso, who am I speaking with today? Hi, my name is Mary Rondo. I'm trying to enroll myself with Contuso. Hi Mary. Uh, are you calling because you need health insurance? Yes, Yeah, I'm calling to sign up for insurance. Great. Uh, if you can answer a few questions, uh, we can get you signed up in a jiffy. OK, So, uh, what's your full name?\n",
      "Recognized: Uh, so Mary Beth Rondo, last name is R like Romeo, O like ocean, N like Nancy, DD like Dog, and O like Ocean again.\n",
      "Recognized: Rondo got it. And what's the best callback number in case we get disconnected?\n",
      "Recognized: I only have a cell phone, so I can give you that. Yeah, that would be fine. Sure. So it's 234554 and then 9312. Got it. So to confirm, it's 234-554-9312.\n",
      "Recognized: Yep, that's right. Excellent. Let's get some additional information from your from your application. Do you have a job?\n",
      "Recognized: Yes, I am self-employed. OK, so then you have a Social Security number as well? Yes, I do. OK and what is your Social Security number please?\n",
      "Recognized: Sure. So it's 412256789. Sorry, what was that A25 or A225 you cut out for a bit?\n",
      "Recognized: It's 22, so 412, then another two, then 5. Alright, thank you so much. And could I have your e-mail address pleaseyeahitsmaryrondo@gmail.com? So myfirstandlastname@gmail.com. No periods, no dashes.\n",
      "Recognized: Great. That is the last question. So let me take your information and I'll be able to get you signed up right away. Thank you for calling Contoso and I'll be able to get you signed up immediately. One of our agents will call you back in about 24 hours or so to confirm your application. That sounds great. Thank you. Absolutely. If you need anything else, please give us a call at 1-800-555-5564 ext 123. Uh, thank you very much for calling Contessa.\n",
      "Recognized: Actually, I have one more question. Yes, of course. I'm curious, will I be getting a physical card as proof of coverage?\n",
      "Recognized: So the default is a digital membership card, but we can send you a physical card if you prefer.\n",
      "Recognized: Yes. Could you please mail it to me when it's ready? I'd like to have it shipped to umm, or my address. Uh yeah. Uh, so it's 2660 Unit A on Maple Ave. SE, Lansing, and then zip code is 48823.\n",
      "Recognized: Absolutely. I've made a note on your file.\n",
      "Recognized: Awesome. Thanks so much. You're very welcome. Thank you for calling Contoso and have a great day.\n",
      "CLOSING on SpeechRecognitionCanceledEventArgs(session_id=80903f08680743afbf152f623b4bc862, result=SpeechRecognitionResult(result_id=bf64f349857b437fb1675afd4099b993, text=\"\", reason=ResultReason.Canceled))\n",
      "CLOSING on SessionEventArgs(session_id=80903f08680743afbf152f623b4bc862)\n",
      "Transcription: Hello, thank you for calling Contoso, who am I speaking with today? Hi, my name is Mary Rondo. I'm trying to enroll myself with Contuso. Hi Mary. Uh, are you calling because you need health insurance? Yes, Yeah, I'm calling to sign up for insurance. Great. Uh, if you can answer a few questions, uh, we can get you signed up in a jiffy. OK, So, uh, what's your full name? Uh, so Mary Beth Rondo, last name is R like Romeo, O like ocean, N like Nancy, DD like Dog, and O like Ocean again. Rondo got it. And what's the best callback number in case we get disconnected? I only have a cell phone, so I can give you that. Yeah, that would be fine. Sure. So it's 234554 and then 9312. Got it. So to confirm, it's 234-554-9312. Yep, that's right. Excellent. Let's get some additional information from your from your application. Do you have a job? Yes, I am self-employed. OK, so then you have a Social Security number as well? Yes, I do. OK and what is your Social Security number please? Sure. So it's 412256789. Sorry, what was that A25 or A225 you cut out for a bit? It's 22, so 412, then another two, then 5. Alright, thank you so much. And could I have your e-mail address pleaseyeahitsmaryrondo@gmail.com? So myfirstandlastname@gmail.com. No periods, no dashes. Great. That is the last question. So let me take your information and I'll be able to get you signed up right away. Thank you for calling Contoso and I'll be able to get you signed up immediately. One of our agents will call you back in about 24 hours or so to confirm your application. That sounds great. Thank you. Absolutely. If you need anything else, please give us a call at 1-800-555-5564 ext 123. Uh, thank you very much for calling Contessa. Actually, I have one more question. Yes, of course. I'm curious, will I be getting a physical card as proof of coverage? So the default is a digital membership card, but we can send you a physical card if you prefer. Yes. Could you please mail it to me when it's ready? I'd like to have it shipped to umm, or my address. Uh yeah. Uh, so it's 2660 Unit A on Maple Ave. SE, Lansing, and then zip code is 48823. Absolutely. I've made a note on your file. Awesome. Thanks so much. You're very welcome. Thank you for calling Contoso and have a great day.\n"
     ]
    }
   ],
   "source": [
    "#Full transcription\n",
    "source = \"./data/Call1_separated_16k_health_insurance.wav\"\n",
    "transcription_full = speech_from_file_full(source)\n",
    "print(f\"Transcription: {transcription_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated to Chinese: 您好，感谢您致电Contoso，请问今天我在和谁通话？您好，我叫Mary Rondo。我想注册Contuso。你好，Mary。请问您是因为需要健康保险而打电话吗？是的，我打电话是为了注册保险。太好了。如果您能回答几个问题，我们可以很快为您注册。好的，那么，您的全名是什么？是Mary Beth Rondo，姓氏是R像Romeo，O像ocean，N像Nancy，DD像Dog，O像Ocean。Rondo，明白了。以防我们断线，您最好的回拨号码是多少？我只有手机，所以我可以给您这个号码。好的，那就行。好的，是234554然后是9312。明白了。确认一下，是234-554-9312。是的，没错。太好了。让我们从您的申请中获取一些额外信息。您有工作吗？是的，我是自雇人士。好的，那么您也有社会安全号码吗？是的，我有。好的，请问您的社会安全号码是多少？当然，是412256789。抱歉，您刚才说的是A25还是A225？您刚才断了一下。是22，所以是412，然后再一个2，然后是5。好的，非常感谢。请问您的电子邮件地址是什么？是的，itsmaryrondo@gmail.com。就是我的名字和姓氏@gmail.com。没有句号，没有破折号。好的。这是最后一个问题。让我记录您的信息，我会立即为您注册。感谢您致电Contoso，我会立即为您注册。我们的代理将在大约24小时内给您回电以确认您的申请。听起来不错，谢谢。绝对的。如果您还有其他需要，请拨打1-800-555-5564分机123联系我们。非常感谢您致电Contessa。实际上，我还有一个问题。好的，当然。我想知道，我会收到一张实体卡作为保险证明吗？默认情况下是数字会员卡，但如果您愿意，我们可以寄给您一张实体卡。好的。请在准备好后邮寄给我，我想寄到我的地址。好的，是2660号A单元，Maple Ave. SE，Lansing，邮政编码是48823。好的，我已经在您的档案中做了记录。太好了，非常感谢。非常欢迎。感谢您致电Contoso，祝您有美好的一天。\n"
     ]
    }
   ],
   "source": [
    "# Translate the text to Chinese using OpenAI\n",
    "translated_text_full = translate(transcription_full, \"Chinese\")\n",
    "print(f\"Translated to Chinese: {translated_text_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response to speech using text-to-speech\n",
    "# In Azure Speech, Speech Synthesis Markup Language (SSML) can be used to specifu different voices.\n",
    "text_to_speech(translated_text_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: Hello, thank you for calling Contoso, who am I speaking with today? Hi, my name is Mary Rondo. I'm trying to enroll myself with Contuso. Hi Mary. Uh, are you calling because you need health insurance? Yes, Yeah, I'm calling to sign up for insurance. Great. Uh, if you can answer a few questions, uh, we can get you signed up in a jiffy. OK. Umm, So, uh, what's your full name?\n"
     ]
    }
   ],
   "source": [
    "#The speech_from_file_short function use recognize_once() method. It is designed for short, single utterances and has a default limit of about 30 seconds for demo purpose.\n",
    "source = \"./data/Call1_separated_16k_health_insurance.wav\"\n",
    "transcription_short = speech_from_file_short(source)\n",
    "print(f\"Transcription: {transcription_short}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the sentiment using OpenAI\n",
    "response = evaluate_sentiment(transcription_short)\n",
    "print(f\"Sentiment: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: {\n",
      "  \"caller_name\": \"Mary Rondo\",\n",
      "  \"call_purpose\": \"sign up for insurance\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "entities = extract_entities(transcription_short)\n",
    "print(f\"Entities: {entities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated to Chinese: 您好，感谢您致电Contoso，请问我今天在和谁通话？您好，我叫玛丽·隆多。我想注册Contoso。您好，玛丽。请问您是因为需要健康保险而打电话吗？是的，我打电话是为了注册保险。好的，如果您能回答几个问题，我们可以很快为您注册。好的，那么，您的全名是什么？\n"
     ]
    }
   ],
   "source": [
    "# Translate the text to Chinese using OpenAI\n",
    "translated_text_short = translate(transcription_short, \"Chinese\")\n",
    "print(f\"Translated to Chinese: {translated_text_short}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response to speech using text-to-speech\n",
    "text_to_speech(translated_text_short)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
