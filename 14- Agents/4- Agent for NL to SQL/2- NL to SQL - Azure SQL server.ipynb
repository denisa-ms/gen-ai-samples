{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a basic SQL agent that translates natural language questions into SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Annotated, Dict\n",
    "\n",
    "from autogen import ConversableAgent, UserProxyAgent, AssistantAgent, config_list_from_json\n",
    "from dotenv import load_dotenv\n",
    "import autogen\n",
    "from typing import Annotated\n",
    "from openai import AzureOpenAI\n",
    "import sqlite3\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.utilities.sql_database import SQLDatabase\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_ENDPOINT=os.getenv(\"AISTUDIO_AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_GPT4o_DEPLOYMENT=os.getenv(\"AI_STUDIO_AZURE_OPENAI_GPT4o_DEPLOYMENT\")\n",
    "AZURE_OPENAI_API_VERSION=\"2024-02-01\"\n",
    "AZURE_OPENAI_KEY=os.getenv(\"AISTUDIO_AZURE_OPENAI_KEY\")\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=AZURE_OPENAI_KEY,\n",
    "        api_version=AZURE_OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Implementation\n",
    "\n",
    "Using AutoGen, a SQL agent can be implemented with an agent. It executes the generated SQL query and the agent can take execution results as feedback to improve its generation in multiple rounds of conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"cache_seed\": 45,  # change the cache_seed for different trials\n",
    "    \"temperature\": 0,\n",
    "    \"timeout\": 120,  # in seconds\n",
    "    \"config_list\": \n",
    "    [\n",
    "        {\n",
    "            \"model\": AZURE_OPENAI_GPT4o_DEPLOYMENT,\n",
    "            \"api_type\": \"azure\",\n",
    "            \"api_key\": AZURE_OPENAI_KEY,\n",
    "            \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "            \"api_version\": AZURE_OPENAI_API_VERSION\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture  \n",
    "### Architecture 1: Few Shot SQL Generation \n",
    "![Architecture 2: Few Shot SQL Generation](./assets/Few%20Shot%20SQL%20generation.png)  \n",
    "\n",
    "If your schema is more complex, you can use a Vector DB to store the tables definitions (the metadata) and use a RAG agent \n",
    "to get the relevant table information to send as a schema.\n",
    "### Architecture 2: Few Shot SQL Generation with RAG\n",
    "![Architecture 2: Few Shot SQL Generation with RAG](./assets/Few%20Shot%20SQL%20Generation%20with%20RAG.png)\n",
    "\n",
    "Sources:\n",
    "[NL to SQL Architecture Alternatives](https://techcommunity.microsoft.com/blog/azurearchitectureblog/nl-to-sql-architecture-alternatives/4136387)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema= \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Authors (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            name TEXT NOT NULL,\n",
    "            biography TEXT\n",
    "        );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS Publishers (\n",
    "        d INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT NOT NULL,\n",
    "        address TEXT\n",
    "    );      \n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS Books (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        title TEXT NOT NULL,\n",
    "        price REAL,\n",
    "        author_id INTEGER NOT NULL, FOREIGN KEY (author_id) REFERENCES Authors(id)\n",
    "    ); \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_termination(msg: Dict):\n",
    "    if \"tool_responses\" not in msg:\n",
    "        return False\n",
    "    json_str = msg[\"tool_responses\"][0][\"content\"]\n",
    "    obj = json.loads(json_str)\n",
    "    return \"error\" not in obj or obj[\"error\"] is None and obj[\"reward\"] == 1\n",
    "\n",
    "\n",
    "# using the Few-shot approach to train the model\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    description=\"Call this agent .\",\n",
    "    system_message=\"\"\"\n",
    "    You are a helpful assistant. You must always reply with some form of text.\n",
    "    All questions not related to the Bookstore SQL database should be answered with the response :\n",
    "    \"I am an expert at providing facts from an SQL Database. Please ask me a question related to SQL only\"\n",
    "    Answer with TERMINATE if you want to end the conversation.\n",
    "   \n",
    "    If the question is related to the Bookstore SQL database, answer the question by turning the SQL result you are given to \n",
    "    a truthful and accurate natural language response to the original question.\n",
    "    For example:\n",
    "\n",
    "    User Question: How many books are there in the bookstore?\n",
    "    Answer: There are 10 books in the bookstore.\n",
    "\n",
    "    User Question: How many books by Herman Melville are in the bookstore?\n",
    "    Answer: There are 0 books in the bookstore written by Herman Melville.\n",
    "\n",
    "    User Question: How many publishers for the book Moby Dick?\n",
    "    Answer: There is no information about publishers in the bookstore.\n",
    "\n",
    "    User Question: What is the weather?\n",
    "    Answer: I am an expert at providing facts from a SQL Database. Please ask me a question related to SQL only.\n",
    "    \n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=check_termination,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_writer = AssistantAgent(\n",
    "    name=\"sql_writer\",\n",
    "    description=\"Call this agent when the questions is related to the Bookstore DB.\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    You are good at writing SQL queries for a bookstore DB.\n",
    "    Use the DB schema below to answer the questions:\n",
    "    {schema}\n",
    "    Always respond with a function call to execute_sql().\n",
    "    \"\"\",\n",
    "    is_termination_msg=check_termination,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\", \n",
    "    human_input_mode=\"NEVER\", \n",
    "    max_consecutive_auto_reply=5, \n",
    "    code_execution_config={\n",
    "        \"work_dir\":\"coding\", \n",
    "        \"use_docker\":False\n",
    "    }\n",
    ")\n",
    "\n",
    "@sql_writer.register_for_llm(description=\"Function for executing SQL query and returning a response\")\n",
    "@user_proxy.register_for_execution()\n",
    "def execute_sql(sql: Annotated[str, \"SQL query\"]) -> Annotated[str, \"results\"]:\n",
    "    database = 'bookstore.db'\n",
    "\n",
    "    conn = sqlite3.connect(database)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cur.execute(sql)\n",
    "        rows = cur.fetchall()\n",
    "        return rows\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": \"The SQL query returned an incorrect result\",\n",
    "            \"wrong_result\": str(e)\n",
    "        }\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_chat = autogen.GroupChat(\n",
    "    agents=[user_proxy, sql_writer, assistant], messages=[], max_round=5\n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=group_chat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "How many books are in the bookstore?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: sql_writer\n",
      "\u001b[0m\n",
      "\u001b[33msql_writer\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_D4R8icvQ4hEgPIxdXml74KLc): execute_sql *****\u001b[0m\n",
      "Arguments: \n",
      "{\"sql\":\"SELECT COUNT(*) FROM books;\"}\n",
      "\u001b[32m****************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: user_proxy\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION execute_sql...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_D4R8icvQ4hEgPIxdXml74KLc) *****\u001b[0m\n",
      "[[2]]\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'How many books are in the bookstore?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'None', 'tool_calls': [{'id': 'call_D4R8icvQ4hEgPIxdXml74KLc', 'function': {'arguments': '{\"sql\":\"SELECT COUNT(*) FROM books;\"}', 'name': 'execute_sql'}, 'type': 'function'}], 'name': 'sql_writer', 'role': 'assistant'}, {'content': '[[2]]', 'tool_responses': [{'tool_call_id': 'call_D4R8icvQ4hEgPIxdXml74KLc', 'role': 'tool', 'content': '[[2]]'}], 'role': 'tool', 'name': 'user_proxy'}], summary='[[2]]', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How many books are in the bookstore?\"\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=question,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "what is the weather?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "I am an expert at providing facts from an SQL Database. Please ask me a question related to SQL only.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: user_proxy\n",
      "\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: user_proxy\n",
      "\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "I am an expert at providing facts from an SQL Database. Please ask me a question related to SQL only.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'what is the weather?', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'I am an expert at providing facts from an SQL Database. Please ask me a question related to SQL only.', 'name': 'assistant', 'role': 'user'}, {'content': '', 'role': 'assistant', 'name': 'user_proxy'}, {'content': '', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'I am an expert at providing facts from an SQL Database. Please ask me a question related to SQL only.', 'name': 'assistant', 'role': 'user'}], summary='I am an expert at providing facts from an SQL Database. Please ask me a question related to SQL only.', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what is the weather?\"\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=question,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_proxy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow many books by Harper Lee are in the bookstore?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241m.\u001b[39minitiate_chat(\n\u001b[0;32m      3\u001b[0m     manager,\n\u001b[0;32m      4\u001b[0m     message\u001b[38;5;241m=\u001b[39mquestion,\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_proxy' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"How many books by Harper Lee are in the bookstore?\"\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=question,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
