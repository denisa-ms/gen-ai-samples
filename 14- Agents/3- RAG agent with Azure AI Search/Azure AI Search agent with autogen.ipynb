{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import json\n",
    "import os\n",
    "from typing import Annotated, Dict\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent, UserProxyAgent, register_function\n",
    "from autogen.cache import Cache\n",
    "from typing import Annotated\n",
    "from typing import Annotated\n",
    "from openai import AzureOpenAI\n",
    "from typing import Annotated\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIParameters\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_ENDPOINT=os.getenv(\"AISTUDIO_AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_GPT4o_DEPLOYMENT=os.getenv(\"AI_STUDIO_AZURE_OPENAI_GPT4o_DEPLOYMENT\")\n",
    "AZURE_OPENAI_API_VERSION=\"2024-02-01\"\n",
    "AZURE_OPENAI_KEY=os.getenv(\"AISTUDIO_AZURE_OPENAI_KEY\")\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "\n",
    "AZURE_SEARCH_SERVICE_ENDPOINT=os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "AZURE_SEARCH_ADMIN_KEY=os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "AZURE_SEARCH_INDEX=os.getenv(\"AZURE_SEARCH_INDEX\")\n",
    "AZURE_SEARCH_SEMANTIC_SEARCH_CONFIG = os.getenv(\"AZURE_SEARCH_SEMANTIC_SEARCH_CONFIG\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API\n",
    "aoai_client = AzureOpenAI(\n",
    "  azure_endpoint = AZURE_OPENAI_GPT4o_DEPLOYMENT, \n",
    "  api_key=AZURE_OPENAI_KEY,  \n",
    "  api_version=AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "\n",
    "llm_config = {\n",
    "    \"cache_seed\": 43,  # change the cache_seed for different trials\n",
    "    \"temperature\": 0,\n",
    "    \"timeout\": 120,  # in seconds\n",
    "    \"config_list\": \n",
    "    [\n",
    "        {\n",
    "            \"model\": AZURE_OPENAI_GPT4o_DEPLOYMENT,\n",
    "            \"api_type\": \"azure\",\n",
    "            \"api_key\": AZURE_OPENAI_KEY,\n",
    "            \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "            \"api_version\": AZURE_OPENAI_API_VERSION\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "aia_search_client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_search():\n",
    "    service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "    key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "    index_name = \"books\"\n",
    "    credential = AzureKeyCredential(key)\n",
    "    return SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "\n",
    "# Generate Document Embeddings using OpenAI Ada Model\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def calc_embeddings(text):\n",
    "    # model = \"deployment_name\"\n",
    "    embeddings = aoai_client.embeddings.create(input = [text], model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME).data[0].embedding\n",
    "    return embeddings\n",
    "\n",
    "# Define your tool function `search` that will interact with the Azure Cognitive Search service.\n",
    "def do_search(query: Annotated[str, \"the information\"]) -> str:\n",
    "    fields = \"embedding\"\n",
    "    embedding = calc_embeddings(query)\n",
    "    vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=fields)\n",
    "  \n",
    "    results = aia_search_client.search(  \n",
    "        search_text=None,  \n",
    "        vector_queries= [vector_query],\n",
    "        select=[\"content\"],\n",
    "    )  \n",
    "\n",
    "    answer = ''\n",
    "    for result in results:  \n",
    "        print(f\"Score: {result['@search.score']}\")  \n",
    "        print(f\"Content: {result['content']}\")  \n",
    "        answer = answer + result['content']\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"Admin\",\n",
    "    system_message=\"A human admin. Interact with the WebSearchEngineer and AzureAISearcher and decides who to assign the task to.\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"code\",\n",
    "        \"use_docker\": False\n",
    "    },\n",
    "    human_input_mode=\"TERMINATE\",\n",
    ")\n",
    "\n",
    "web_search_engineer = autogen.AssistantAgent(\n",
    "    name=\"WebSearchEngineer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"Web Search Engineer. Make sure you save code to disk.  You write python/shell \n",
    "    code to solve tasks. Wrap the code in a code block that specifies the script type and the name of the file to \n",
    "    save to disk.\"\"\",\n",
    ")\n",
    "\n",
    "aia_searcher = autogen.AssistantAgent(\n",
    "    name=\"AzureAISearcher\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "        Assistant who has extra content retrieval power for questions about the Moby Dick's book, only use the functions you have been provided with. \n",
    "        Reply TERMINATE when the task is done.\"\"\",\n",
    ")\n",
    "\n",
    "# Register the tool signature with the assistant agent.\n",
    "aia_searcher.register_for_llm(name=\"do_search\", description=\"Get information about Moby Dick's book by Herman Melville.\")(do_search)\n",
    "# Register the tool function with the user proxy agent.\n",
    "user_proxy.register_for_execution(name=\"do_search\")(do_search)\n",
    "\n",
    "\n",
    "group_chat = autogen.GroupChat(\n",
    "    agents=[user_proxy, web_search_engineer, aia_searcher], messages=[], max_round=12\n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=group_chat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aia_search_client = config_search()\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"Why does the coffin prepared for Queequeg become Ishmael's life buoy once the Pequod sinks?\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "This notebook demonstrates the use of Assistant Agents in conjunction with Azure Cognitive Search and Azure Identity",
   "tags": [
    "RAG",
    "Azure Identity",
    "Azure AI Search"
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "skip_test": "This requires Azure AI Search to be enabled and creds for AI Search from Azure Portal"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
