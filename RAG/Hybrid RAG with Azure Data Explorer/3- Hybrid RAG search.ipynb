{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid RAG with Azure Data Explorer  \n",
    "\n",
    "You can run this notebook after succesfully running these notebooks: \n",
    "- \"1- Create entities and embeddings\" \n",
    "- \"2- Save entities and embeddings into ADX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, JSON, Markdown, Image\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "from azure.kusto.data import KustoClient, KustoConnectionStringBuilder\n",
    "from azure.kusto.data.exceptions import KustoServiceError\n",
    "from azure.kusto.data.helpers import dataframe_from_result_table\n",
    "\n",
    "\n",
    "# Configure environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_GPT4_32k_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4_32k_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "api_version = \"2024-02-01\"\n",
    "\n",
    "AAD_TENANT_ID = os.getenv(\"AAD_TENANT_ID\")\n",
    "KUSTO_CLUSTER = os.getenv(\"KUSTO_CLUSTER\")\n",
    "KUSTO_DATABASE = os.getenv(\"KUSTO_DATABASE\")\n",
    "KUSTO_TABLE = os.getenv(\"KUSTO_TABLE\")\n",
    "KUSTO_MANAGED_IDENTITY_APP_ID = os.getenv(\"KUSTO_MANAGED_IDENTITY_APP_ID\")\n",
    "KUSTO_MANAGED_IDENTITY_SECRET = os.getenv(\"KUSTO_MANAGED_IDENTITY_SECRET\")\n",
    "\n",
    "# define embeddings \n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    openai_api_version=api_version,\n",
    "    chunk_size = 1\n",
    ")\n",
    "\n",
    "# call OpenAI to get the answer\n",
    "clientOpenAI = AzureOpenAI(\n",
    "  azure_endpoint = OPENAI_DEPLOYMENT_ENDPOINT, \n",
    "  api_key=OPENAI_API_KEY,  \n",
    "  api_version=\"2023-05-15\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def call_openAI(messages):\n",
    "    response = clientOpenAI.chat.completions.create(\n",
    "        model=OPENAI_GPT4_32k_DEPLOYMENT_NAME,\n",
    "        messages = messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def calc_embeddings(text):\n",
    "    deployment = OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    txt = text.replace(\"\\n\", \" \")\n",
    "    return embeddings.embed_query(txt)\n",
    "\n",
    "\n",
    "\n",
    "def call_openAI_for_final_answer(question, answer):\n",
    "    prompt = 'Question: {}'.format(question) + '\\n' + 'Information: {}'.format(answer)\n",
    "    # prepare prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a HELPFUL assistant answering users questions. Answer the question using the provided information and do not add anything else.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}]\n",
    "    return call_openAI(messages)\n",
    "\n",
    "def prettyprint(text: str) -> str:\n",
    "    print(textwrap.fill(text, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to adx using AAD app registration\n",
    "cluster = KUSTO_CLUSTER\n",
    "kcsb = KustoConnectionStringBuilder.with_aad_application_key_authentication(cluster, KUSTO_MANAGED_IDENTITY_APP_ID, KUSTO_MANAGED_IDENTITY_SECRET,  AAD_TENANT_ID)\n",
    "client = KustoClient(kcsb)\n",
    "kusto_db = KUSTO_DATABASE\n",
    "embeddings_table = \"aviationIncidentsEmbeddings\"\n",
    "entities_table = \"aviationIncidentsEntities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_adx(question, nr_of_answers=1):\n",
    "        searchedEmbedding = calc_embeddings(question)\n",
    "        kusto_query = embeddings_table + \" | extend similarity = series_cosine_similarity_fl(dynamic(\"+str(searchedEmbedding)+\"), embedding,1,1) | top \" + str(nr_of_answers) + \" by similarity desc \"\n",
    "        response = client.execute(kusto_db, kusto_query)\n",
    "\n",
    "        for row in response.primary_results[0]:\n",
    "                return row['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_in_NL_withOpenAI(question, answers_from_ADX):    \n",
    "    prompt = 'Question: {}'.format(question) + '\\n' + 'Information: {}'.format(answers_from_ADX)\n",
    "    # prepare prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": \"\"\"You are a HELPFUL assistant answering users questions. \n",
    "                Answer the question using the provided information only and do not add anything else.\n",
    "                \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    result = call_openAI(messages)\n",
    "    display(HTML(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use GPT4 to translate the question to KQL\n",
    "def generate_KQL_query(question):\n",
    "    question_formatted = f\"\"\"You are a HELPFUL assistant translating Natural language to KQL queries. \n",
    "               \n",
    "                The Table in the database is called \"aviationIncidentsEntities\" and it has the following fields:\n",
    "                'document_id','document_name', 'entities'\n",
    "                The 'entities' field is a KQL dynamic field that contains the following properties:\n",
    "                aircraft_make:'',accident_number:'',aircraft_damage:'',city:'', state:'', country:'', phase_of_operation:'', pilot_flight_hours:'', engine_manufacturer:''\n",
    "                \n",
    "                Answer with the KQL query ONLY and do not add anything else.\n",
    "                \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": question_formatted},\n",
    "                {\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "    result = call_openAI(messages)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KQL query: aviationIncidentsEntities\n",
      "| where entities.country == \"USA\"\n",
      "| project entities.accident_number\n",
      "Number of results: 6\n",
      "List of accident numbers: NYC08CA055, SEA08CA052, NYC08CA040, NYC08CA073, NYC08CA058, NYC08CA068, \n"
     ]
    }
   ],
   "source": [
    "#We can use GPT4 to generate the KQL query for the question\n",
    "query = generate_KQL_query(\"List all the accidents numbers occurred in the USA?\")\n",
    "print(\"KQL query: \" + query)\n",
    "\n",
    "#run the KQL query\n",
    "response = client.execute(kusto_db, query)\n",
    "nr_of_results = len(response.primary_results[0])\n",
    "print(\"Number of results: \" + str(nr_of_results))\n",
    "\n",
    "#extract the accident numbers\n",
    "list_of_accident_numbers = ''\n",
    "for row in response.primary_results[0]:\n",
    "    txt = (row[\"entities_accident_number\"])\n",
    "    list_of_accident_numbers += txt + ', '\n",
    "print(\"List of accident numbers: \" + list_of_accident_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do Hybrid RAG with OpenAI and ADX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of doc ids: 27f7c1d2-be1e-4141-b58a-3d50ba51def7, e47b1c8f-8057-4cd6-9584-25e01d0e64c3, c7c452bc-5403-4fa4-94ce-25596f703445, b125d53a-5a77-42d6-a164-e993d6c11929, 9ed0cf6e-e434-4981-afc7-45fa4c37e02d, ae7c2761-faa5-4b41-a91f-2f02cfd77531, \n"
     ]
    }
   ],
   "source": [
    "#search for all the accidents that occurred in the USA- grab the document_id\n",
    "query = \"\"\"\n",
    " aviationIncidentsEntities\n",
    "| where entities.country == \"USA\"\n",
    "| project document_id\n",
    "\"\"\"\n",
    "\n",
    "#run the KQL query\n",
    "response = client.execute(kusto_db, query)\n",
    "nr_of_results = len(response.primary_results[0])\n",
    "\n",
    "#extract the accident numbers\n",
    "list_of_accident_numbers = ''\n",
    "for row in response.primary_results[0]:\n",
    "    txt = (row[\"document_id\"])\n",
    "    list_of_accident_numbers += txt + ', '\n",
    "print(\"List of doc ids: \" + list_of_accident_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a KQL query that will combine ADX query with Vector search\n",
    "def get_embeddings_from_adx_with_prefix(question, query_prefix, nr_of_answers=1):\n",
    "        searchedEmbedding = calc_embeddings(question)\n",
    "        kusto_query = query_prefix + \" | extend similarity = series_cosine_similarity_fl(dynamic(\"+str(searchedEmbedding)+\"), embedding,1,1) | top \" + str(nr_of_answers) + \" by similarity desc \"\n",
    "        response = client.execute(kusto_db, kusto_query)\n",
    "        \n",
    "        txt = ''\n",
    "        for row in response.primary_results[0]:\n",
    "                txt += row['content']\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The first accident in Alton, NH involved a pilot who was flying a Cessna 170B. The pilot decided to make a low pass over a frozen lake, but his depth perception was negatively affected by the flat light and snow on the ground. The right main landing gear contacted the snowy frozen surface, causing the right wing to impact the surface. The airplane sustained substantial damage to the right wing and firewall. The cause of the accident was determined to be the pilot's failure to maintain clearance above the frozen lake while maneuvering, with contributing factors being the pilot's attempt of the low altitude maneuver and unfavorable lighting conditions.\n",
       "\n",
       "The second accident in Fullerton, CA involved a student pilot who was taxiing a Cessna 172S to parking after landing. The pilot was informed by the tower controller about a helicopter above him and to his right. While watching the helicopter, the pilot added right brake and throttle to move the airplane towards the center line of the taxiway. However, the airplane's left wing contacted a utility trailer, causing substantial damage to the wing spar. The cause of the accident was determined to be the pilot's failure to maintain clearance while taxiing, with the contributing factor being the pilot's diverted attention."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"aviationIncidentsEntities | where entities.country == \"USA\" | join aviationIncidentsEmbeddings on $left.document_id == $right.document_id\"\"\"\n",
    "question = \"Accidents involving snow or ice\"\n",
    "adx_results = get_embeddings_from_adx_with_prefix(question, query, 2)\n",
    "answer_in_NL_withOpenAI(question, adx_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphRAG - combining ADX graph capabilities with Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
