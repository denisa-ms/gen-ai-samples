{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create entities and embeddings from Aviation Reports for Hybrid RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from openai import AzureOpenAI\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_GPT4_32k_DEPLOYMENT_NAME = os.getenv(\"OPENAI_GPT4_32k_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "api_version = \"2024-02-01\"\n",
    "\n",
    "AAD_TENANT_ID = os.getenv(\"AAD_TENANT_ID\")\n",
    "KUSTO_CLUSTER = os.getenv(\"KUSTO_CLUSTER\")\n",
    "KUSTO_DATABASE = os.getenv(\"KUSTO_DATABASE\")\n",
    "KUSTO_TABLE = os.getenv(\"KUSTO_TABLE\")\n",
    "KUSTO_MANAGED_IDENTITY_APP_ID = os.getenv(\"KUSTO_MANAGED_IDENTITY_APP_ID\")\n",
    "KUSTO_MANAGED_IDENTITY_SECRET = os.getenv(\"KUSTO_MANAGED_IDENTITY_SECRET\")\n",
    "\n",
    "# define embeddings \n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    azure_endpoint=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    openai_api_version=api_version,\n",
    "    chunk_size = 1\n",
    ")\n",
    "\n",
    "# call OpenAI to get the answer\n",
    "clientOpenAI = AzureOpenAI(\n",
    "  azure_endpoint = OPENAI_DEPLOYMENT_ENDPOINT, \n",
    "  api_key=OPENAI_API_KEY,  \n",
    "  api_version=\"2023-05-15\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def call_openAI(messages):\n",
    "    response = clientOpenAI.chat.completions.create(\n",
    "        model=OPENAI_GPT4_32k_DEPLOYMENT_NAME,\n",
    "        messages = messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "#we use the tenacity library to create delays and retries when calling openAI embeddings to avoid hitting throttling limits\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def calc_embeddings(text):\n",
    "    deployment = OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    txt = text.replace(\"\\n\", \" \")\n",
    "    return embeddings.embed_query(txt)\n",
    "\n",
    "#Use GPT-4 to extract entities from a text\n",
    "def extract_entities(text):\n",
    "    system_message = \"\"\"\n",
    "        You are an assistant designed to extract entities from a text. \n",
    "        Users will paste in a string of text and you will respond with entities you have extracted from the text as a JSON object.\n",
    "        Here is an example of your output format:\n",
    "        {aircraft_make:'',accident_number:'',aircraft_damage:'',city:'', state:'', country:'', phase_of_operation:'', pilot_flight_hours:'', engine_manufacturer:''}\n",
    "    \"\"\"\n",
    "    messages = [{\"role\":\"system\",\"content\":system_message},{\"role\":\"user\",\"content\":text}]\n",
    "    response = call_openAI(messages)\n",
    "    return response\n",
    "\n",
    "\n",
    "def call_openAI_for_final_answer(question, answer):\n",
    "    prompt = 'Question: {}'.format(question) + '\\n' + 'Information: {}'.format(answer)\n",
    "    # prepare prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a HELPFUL assistant answering users questions. Answer the question using the provided information and do not add anything else.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}]\n",
    "    return call_openAI(messages)\n",
    "\n",
    "def prettyprint(text: str) -> str:\n",
    "    print(textwrap.fill(text, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20071229X02007.pdf', '20071231X02009.pdf', '20080102X00002.pdf', '20080102X00005.pdf', '20080117X00064.pdf', '20080117X00072.pdf', '20080122X00080.pdf', '20080123X00097.pdf', '20080124X00100.pdf', '20080124X00101.pdf', '20080124X00101a.pdf', 'processed']\n",
      "Number of pages:  4\n",
      "Entities:  {\"aircraft_make\":\"Piper PA-22-150\",\"accident_number\":\"NYC08CA055\",\"aircraft_damage\":\"Substantial\",\"city\":\"Tallahassee\",\"state\":\"FL\",\"country\":\"USA\",\"phase_of_operation\":\"APPROACH\",\"pilot_flight_hours\":\"2319\",\"engine_manufacturer\":\"Lycoming\"}\n",
      "Number of pages:  4\n",
      "Entities:  {\"city\": \"Death Valley\", \"state\": \"CA\", \"accident_number\": \"SEA08CA049\", \"date_time\": \"11/29/2007, 0830 PST\", \"aircraft_registration\": \"N8770M\", \"aircraft_make\": \"Beech A23\", \"aircraft_damage\": \"Substantial\", \"phase_of_operation\": \"LANDING - FLARE/TOUCHDOWN\", \"pilot_flight_hours\": \"119 hours\", \"engine_manufacturer\": \"Continental\"}\n",
      "Number of pages:  3\n",
      "Entities:  {\"aircraft_make\":\"Reims F172 M\",\"accident_number\":\"DEN08WA042\",\"aircraft_damage\":\"Destroyed\",\"city\":\"Chevroux\", \"state\":\"\", \"country\":\"France\", \"phase_of_operation\":\"\", \"pilot_flight_hours\":\"\", \"engine_manufacturer\":\"Lycoming\"}\n",
      "Number of pages:  4\n",
      "Entities:  {\"city\": \"Belen\", \"state\": \"NM\", \"accident_number\": \"DEN08CA034\", \"date_time\": \"11/27/2007, 1100 MST\", \"aircraft_registration\": \"N74SR\", \"aircraft_make\": \"Godwin, David P Sorrell SNJ-7\", \"aircraft_damage\": \"Substantial\", \"phase_of_operation\": \"LANDING - ROLL\", \"pilot_flight_hours\": \"1364 hours\", \"engine_manufacturer\": \"Lycoming\"}\n",
      "Number of pages:  3\n",
      "Entities:  {\"aircraft_make\":\"Bombardier, Inc. BD-700-1A11\",\"accident_number\":\"NYC08WA076\",\"aircraft_damage\":\"Substantial\",\"city\":\"Charlestown\",\"state\":\"St Kitts And Nevis\",\"country\":\"\",\"phase_of_operation\":\"landing\",\"pilot_flight_hours\":\"\",\"engine_manufacturer\":\"\"}\n",
      "Number of pages:  4\n",
      "Entities:  {\"city\": \"Fullerton\", \"state\": \"CA\", \"accident_number\": \"SEA08CA052\", \"aircraft_damage\": \"Substantial\", \"aircraft_make\": \"Cessna\", \"country\": \"USA\", \"phase_of_operation\": \"TAXI - FROM LANDING\", \"pilot_flight_hours\": \"102 hours\", \"engine_manufacturer\": \"Lycoming\"}\n",
      "Number of pages:  4\n",
      "Entities:  {\"aircraft_make\":\"Piper PA-28-140\",\"accident_number\":\"NYC08CA040\",\"aircraft_damage\":\"Substantial\",\"city\":\"Murfreesboro\",\"state\":\"TN\",\"country\":\"USA\",\"phase_of_operation\":\"LANDING\",\"pilot_flight_hours\":\"435 hours\",\"engine_manufacturer\":\"Lycoming\"}\n",
      "Number of pages:  4\n",
      "Entities:  {\"aircraft_make\":\"Piper PA-31T\",\"accident_number\":\"NYC08CA073\",\"aircraft_damage\":\"Substantial\",\"city\":\"Muscle Shoals\",\"state\":\"AL\",\"country\":\"USA\",\"phase_of_operation\":\"LANDING - FLARE/TOUCHDOWN\",\"pilot_flight_hours\":\"10127\",\"engine_manufacturer\":\"Pratt & Whitney Canada\"}\n",
      "Number of pages:  5\n",
      "Entities:  {\"city\": \"White Plains\", \"state\": \"AL\", \"accident_number\": \"NYC08CA058\", \"aircraft_damage\": \"Substantial\", \"aircraft_make\": \"Fisher Aero Celebrity\", \"country\": \"USA\", \"phase_of_operation\": \"CRUISE\", \"pilot_flight_hours\": \"11423\", \"engine_manufacturer\": \"Continental\"}\n",
      "Number of pages:  4\n",
      "Entities:  {\"aircraft_make\":\"Cessna 170B\",\"accident_number\":\"NYC08CA068\",\"aircraft_damage\":\"Substantial\",\"city\":\"Alton\", \"state\":\"NH\", \"country\":\"USA\", \"phase_of_operation\":\"MANEUVERING\", \"pilot_flight_hours\":\"1700\", \"engine_manufacturer\":\"Continental\"}\n",
      "Number of pages:  5\n",
      "Entities:  {\"aircraft_make\":\"Cessna 170B\",\"accident_number\":\"NYC08CA068\",\"aircraft_damage\":\"Substantial\",\"city\":\"Alton\",\"state\":\"NY\",\"country\":\"\",\"phase_of_operation\":\"MANEUVERING\",\"pilot_flight_hours\":\"1700\",\"engine_manufacturer\":\"Continental\"}\n"
     ]
    }
   ],
   "source": [
    "# splitting into 5000 char long chunks with 30 char overlap\n",
    "# split [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "import uuid\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=10000,chunk_overlap=100)\n",
    "\n",
    "pdf_folder_path = \"./data/\"\n",
    "print(os.listdir(pdf_folder_path))\n",
    "\n",
    "# read the pdf files and split them into chunks, extract entities and calculate embeddings\n",
    "embeddings_df = pd.DataFrame(columns=['document_id','document_name', 'content', 'embedding'])\n",
    "entities_df = pd.DataFrame(columns=['document_id','document_name', 'entities'])\n",
    "\n",
    "for file in os.listdir(pdf_folder_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        # generate a unique guid for the document\n",
    "        id = uuid.uuid4()\n",
    "        pdf_path = os.path.join(pdf_folder_path, file)\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        # calculate embeddings\n",
    "        pages = loader.load_and_split(text_splitter=splitter)\n",
    "        print(\"Number of pages: \", len(pages))\n",
    "        all_pages = ''\n",
    "        for page in pages:\n",
    "            #save all the pages into a pandas dataframe\n",
    "            embeddings_df.loc[len(embeddings_df.index)] = [id, file, page.page_content, \"\"]  \n",
    "            all_pages += page.page_content\n",
    "\n",
    "        # extract entities from the whole document - we assume the document is less than 32k tokens (we are using GPT4 32k model)\n",
    "        entities = (extract_entities(all_pages))\n",
    "        print(\"Entities: \", entities)\n",
    "        entities_df.loc[len(entities_df.index)] = [id, file, entities]  \n",
    "\n",
    "# calculate the embeddings using openAI ada \n",
    "embeddings_df[\"embedding\"] = embeddings_df.content.apply(lambda x: calc_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entities_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# save the dataframes to csv files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mentities_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/processed/entities.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m embeddings_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/processed/embeddings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'entities_df' is not defined"
     ]
    }
   ],
   "source": [
    "# save the dataframes to csv files\n",
    "entities_df.to_csv('./data/processed/entities.csv', index=False)\n",
    "embeddings_df.to_csv('./data/processed/embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
